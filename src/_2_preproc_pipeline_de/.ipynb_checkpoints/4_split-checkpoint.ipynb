{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-12T12:41:42.574247Z",
     "start_time": "2024-04-12T12:41:41.926005Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "random_seed = 42\n",
    "data_path = \"../data_preprocessed/amazon_total_unified.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209991 entries, 0 to 209990\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      209991 non-null  object\n",
      " 1   label   209991 non-null  int64 \n",
      " 2   tokens  209991 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T12:41:51.040707Z",
     "start_time": "2024-04-12T12:41:42.576243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "df[\"tokens\"] = df[\"tokens\"].apply(ast.literal_eval)"
   ],
   "id": "98132c01018c0370",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T12:41:51.055917Z",
     "start_time": "2024-04-12T12:41:51.041498Z"
    }
   },
   "cell_type": "code",
   "source": "df['label'] = df['label'].astype(int)",
   "id": "84186bbde312a9e7",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T12:43:27.813570Z",
     "start_time": "2024-04-12T12:43:27.772571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tokens'], df['label'],\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=random_seed,\n",
    "                                                    stratify=df['label'])\n",
    "\n",
    "# Splitting the training dataset further into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                      test_size=0.25, \n",
    "                                                      random_state=random_seed,\n",
    "                                                      stratify=y_train)"
   ],
   "id": "b0196789eb798277",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Splitting the dataset into training and testing sets\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtokens\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                                                    \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                                                    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                                                    \u001B[49m\u001B[43mstratify\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Splitting the training dataset further into training and validation sets\u001B[39;00m\n\u001B[0;32m     10\u001B[0m X_train, X_valid, y_train, y_valid \u001B[38;5;241m=\u001B[39m train_test_split(X_train, y_train,\n\u001B[0;32m     11\u001B[0m                                                       test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m, \n\u001B[0;32m     12\u001B[0m                                                       random_state\u001B[38;5;241m=\u001B[39mrandom_seed,\n\u001B[0;32m     13\u001B[0m                                                       stratify\u001B[38;5;241m=\u001B[39my_train)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2152\u001B[0m, in \u001B[0;36mtrain_test_split\u001B[1;34m(*arrays, **options)\u001B[0m\n\u001B[0;32m   2146\u001B[0m         CVClass \u001B[38;5;241m=\u001B[39m ShuffleSplit\n\u001B[0;32m   2148\u001B[0m     cv \u001B[38;5;241m=\u001B[39m CVClass(test_size\u001B[38;5;241m=\u001B[39mn_test,\n\u001B[0;32m   2149\u001B[0m                  train_size\u001B[38;5;241m=\u001B[39mn_train,\n\u001B[0;32m   2150\u001B[0m                  random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[1;32m-> 2152\u001B[0m     train, test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marrays\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstratify\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(chain\u001B[38;5;241m.\u001B[39mfrom_iterable((_safe_indexing(a, train),\n\u001B[0;32m   2155\u001B[0m                                  _safe_indexing(a, test)) \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m arrays))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1341\u001B[0m, in \u001B[0;36mBaseShuffleSplit.split\u001B[1;34m(self, X, y, groups)\u001B[0m\n\u001B[0;32m   1311\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001B[39;00m\n\u001B[0;32m   1312\u001B[0m \n\u001B[0;32m   1313\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1338\u001B[0m \u001B[38;5;124;03mto an integer.\u001B[39;00m\n\u001B[0;32m   1339\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1340\u001B[0m X, y, groups \u001B[38;5;241m=\u001B[39m indexable(X, y, groups)\n\u001B[1;32m-> 1341\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iter_indices(X, y, groups):\n\u001B[0;32m   1342\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m train, test\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1692\u001B[0m, in \u001B[0;36mStratifiedShuffleSplit._iter_indices\u001B[1;34m(self, X, y, groups)\u001B[0m\n\u001B[0;32m   1687\u001B[0m rng \u001B[38;5;241m=\u001B[39m check_random_state(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_state)\n\u001B[0;32m   1689\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_splits):\n\u001B[0;32m   1690\u001B[0m     \u001B[38;5;66;03m# if there are ties in the class-counts, we want\u001B[39;00m\n\u001B[0;32m   1691\u001B[0m     \u001B[38;5;66;03m# to make sure to break them anew in each iteration\u001B[39;00m\n\u001B[1;32m-> 1692\u001B[0m     n_i \u001B[38;5;241m=\u001B[39m \u001B[43m_approximate_mode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclass_counts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrng\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1693\u001B[0m     class_counts_remaining \u001B[38;5;241m=\u001B[39m class_counts \u001B[38;5;241m-\u001B[39m n_i\n\u001B[0;32m   1694\u001B[0m     t_i \u001B[38;5;241m=\u001B[39m _approximate_mode(class_counts_remaining, n_test, rng)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\sklearn\\utils\\__init__.py:1102\u001B[0m, in \u001B[0;36m_approximate_mode\u001B[1;34m(class_counts, n_draws, rng)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m need_to_add \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1101\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m floored\u001B[38;5;241m.\u001B[39mastype(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ml_angew_programm\\lib\\site-packages\\numpy\\__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[1;34m(attr)\u001B[0m\n\u001B[0;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[1;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[0;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[0;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[0;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5f83b13cce8c0589",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
